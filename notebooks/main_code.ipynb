{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e47a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional\n",
    "import pyaudio\n",
    "import struct\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import pvporcupine\n",
    "from ollama import generate\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "ACCESS_KEY = \"O6Jn/TyI+Rcl7jYPPB6QmEk3as4RzWcFuQv6k1dCICtl7BGyUHeYsA==\"\n",
    "API_KEY = \"sk_f810c561808f533447a6d19093bc1cff201352a1a880acfb\"\n",
    "VOICE_ID = \"nPczCjzI2devNBz1zQrb\"\n",
    "CAMERA_URL = \"http://192.168.105.196/\"  # important change to the camera IP\n",
    "\n",
    "MIC_INDEX = 0\n",
    "TIMEOUT = 5\n",
    "SAMPLE_RATE = 16000  # Could be reduced to 8000 if Whisper performs well\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class VisionAssistant:\n",
    "    def __init__(self, whisper_model_size: str = \"base\"):\n",
    "        \"\"\"Initialize the Vision Assistant with specified Whisper model size.\"\"\"\n",
    "        self.pa = pyaudio.PyAudio()\n",
    "        self.porcupine = pvporcupine.create(\n",
    "            access_key=ACCESS_KEY,\n",
    "            keyword_paths=[\"Hey-Vision_en_windows_v3_0_0.ppn\"]\n",
    "        )\n",
    "        self.audio_stream = self.pa.open(\n",
    "            rate=self.porcupine.sample_rate,\n",
    "            channels=1,\n",
    "            format=pyaudio.paInt16,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.porcupine.frame_length,\n",
    "            input_device_index=MIC_INDEX\n",
    "        )\n",
    "        self.whisper_model = whisper.load_model(whisper_model_size)\n",
    "        self.executor = ThreadPoolExecutor(max_workers=2)\n",
    "        self.shutdown_flag = False\n",
    "        self.is_active = False  # General mode\n",
    "        self.is_assistance_mode = False  # Assistance mode\n",
    "        self.is_currency_mode = False\n",
    "        self.currency_model = YOLO(\"currency.pt\")\n",
    "        self.is_call_mode = False        # Call mode\n",
    "        self.is_hazards_mode = False     # Hazards mode\n",
    "        self.hazard_model = YOLO(\"hazard.pt\")\n",
    "        self.tts_engine = pyttsx3.init()\n",
    "        self.tts_engine.setProperty('rate', 175)  # Speed of speech\n",
    "        self.tts_engine.setProperty('volume', 1.0)  # Max volume\n",
    "\n",
    "\n",
    "    def record_audio(self, duration: int = TIMEOUT, max_size_mb: float = 10.0) -> str:\n",
    "        \"\"\"Record audio from microphone and save to temporary WAV file.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Recording audio for %d seconds...\", duration)\n",
    "            audio = sd.rec(\n",
    "                int(duration * SAMPLE_RATE),\n",
    "                samplerate=SAMPLE_RATE,\n",
    "                channels=1,\n",
    "                dtype='int16',\n",
    "                device=MIC_INDEX\n",
    "            )\n",
    "            sd.wait()\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                with wave.open(temp_file.name, 'wb') as wf:\n",
    "                    wf.setnchannels(1)\n",
    "                    wf.setsampwidth(2)\n",
    "                    wf.setframerate(SAMPLE_RATE)\n",
    "                    wf.writeframes(audio.tobytes())\n",
    "                \n",
    "                if os.path.getsize(temp_file.name) > max_size_mb * 1024 * 1024:\n",
    "                    logger.warning(\"Audio file exceeds maximum size\")\n",
    "                    os.unlink(temp_file.name)\n",
    "                    return None\n",
    "                logger.info(\"Audio recorded to %s\", temp_file.name)\n",
    "                return temp_file.name\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Audio recording failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def recognize_speech(self, audio_path: str) -> Optional[str]:\n",
    "        \"\"\"Transcribe audio using Whisper.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Transcribing audio from %s\", audio_path)\n",
    "            result = self.whisper_model.transcribe(audio_path)\n",
    "            os.unlink(audio_path)\n",
    "            logger.info(\"Transcription result: %s\", result[\"text\"])\n",
    "            return result[\"text\"]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Speech recognition failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def process_image(self, img: Image.Image, command: str) -> str:\n",
    "        \"\"\"Process image using ollama model (faster version).\"\"\"\n",
    "        try:\n",
    "            max_size = (96, 96)\n",
    "            img.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            with BytesIO() as buffer:\n",
    "                img.save(buffer, format='PNG')\n",
    "                image_bytes = buffer.getvalue()\n",
    "\n",
    "            full_response = ''\n",
    "            for response in generate(\n",
    "                model='llava:7b-v1.6',\n",
    "                prompt=command,\n",
    "                images=[image_bytes],\n",
    "                stream=True\n",
    "            ):\n",
    "                full_response += response['response']\n",
    "            return full_response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Image processing failed: {str(e)}\")\n",
    "            return \"Error processing image\"\n",
    "\n",
    "    def speak_text(self, text: str) -> None:\n",
    "        \"\"\"Speak text locally using pyttsx3 (fast and offline).\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Speaking (local): {text}\")\n",
    "            self.tts_engine.say(text)\n",
    "            self.tts_engine.runAndWait()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Local TTS failed: {str(e)}\")\n",
    "    \n",
    "    def capture_image(self, max_attempts: int = 2):\n",
    "        \"\"\"Capture a single frame from MJPEG stream (faster attempts).\"\"\"\n",
    "        boundary = b\"--123456789000000000000987654321\"\n",
    "\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                with requests.get(CAMERA_URL, stream=True, timeout=3) as response:\n",
    "                    if response.status_code != 200:\n",
    "                        raise Exception(f\"Bad response code: {response.status_code}\")\n",
    "\n",
    "                    buffer = b\"\"\n",
    "                    for chunk in response.iter_content(chunk_size=512):\n",
    "                        buffer += chunk\n",
    "\n",
    "                        start = buffer.find(b\"\\xff\\xd8\")\n",
    "                        end = buffer.find(b\"\\xff\\xd9\")\n",
    "\n",
    "                        if start != -1 and end != -1 and end > start:\n",
    "                            jpeg_data = buffer[start:end+2]\n",
    "                            return Image.open(BytesIO(jpeg_data))\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                time.sleep(1)\n",
    "\n",
    "        logger.error(\"Failed to capture image from MJPEG stream.\")\n",
    "        return None\n",
    "    \n",
    "    def process_command(self, command: str) -> None:\n",
    "        \"\"\"Handle user command with faster flow and parallel tasks.\"\"\"\n",
    "        self.speak_text(f\"Did you mean: {command}? Please say 'yes' or 'no'\")\n",
    "\n",
    "        audio_path = self.record_audio(duration=2)\n",
    "        if audio_path:\n",
    "            confirmation = self.recognize_speech(audio_path)\n",
    "            if confirmation:\n",
    "                logger.info(f\"Confirmation received: {confirmation}\")\n",
    "                if \"yes\" in confirmation.lower():\n",
    "                    self.speak_text(\"Processing your command\")\n",
    "\n",
    "                    img_result = {}\n",
    "                    def capture(): img_result['image'] = self.capture_image()\n",
    "\n",
    "                    capture_thread = threading.Thread(target=capture)\n",
    "                    capture_thread.start()\n",
    "                    capture_thread.join(timeout=3)\n",
    "\n",
    "                    image = img_result.get('image')\n",
    "                    if image:\n",
    "                        try:\n",
    "                            caption = self.process_image(image, command)\n",
    "                            if caption and caption != \"Error processing image\":\n",
    "                                self.speak_text(caption)\n",
    "                                logger.info(f\"Command processed successfully. Result: {caption}\")\n",
    "                            else:\n",
    "                                self.speak_text(\"Sorry, I couldn't process the image\")\n",
    "                                logger.warning(\"Image processing failed or returned no result\")\n",
    "                        except Exception as e:\n",
    "                            self.speak_text(\"An error occurred while processing your command\")\n",
    "                            logger.error(f\"Command processing error: {str(e)}\")\n",
    "                    else:\n",
    "                        self.speak_text(\"Failed to capture an image from the camera\")\n",
    "                        logger.error(\"Image capture failed\")\n",
    "                else:\n",
    "                    self.speak_text(\"Command cancelled\")\n",
    "                    logger.info(\"Command cancelled by user\")\n",
    "            else:\n",
    "                self.speak_text(\"I didn't hear your confirmation\")\n",
    "                logger.warning(\"No confirmation received\")\n",
    "        else:\n",
    "            self.speak_text(\"Failed to record your confirmation. Command cancelled\")\n",
    "            logger.warning(\"Failed to record confirmation\")\n",
    "\n",
    "    \n",
    "    def detect_currency(self):\n",
    "        try:\n",
    "            logger.info(\"Starting currency detection...\")\n",
    "            self.speak_text(\"Say 'stop' when you want to end the session.\")\n",
    "\n",
    "            if self.currency_model is None:\n",
    "                logger.error(\"YOLO model not initialized\")\n",
    "                self.speak_text(\"Currency detection not available. YOLO model not initialized.\")\n",
    "                return\n",
    "\n",
    "            last_announcement_time = {}\n",
    "            announcement_cooldown = 3\n",
    "            stream = requests.get(CAMERA_URL, stream=True)\n",
    "\n",
    "            if stream.status_code != 200:\n",
    "                self.speak_text(\"Failed to connect to the camera\")\n",
    "                logger.error(\"Camera connection failed\")\n",
    "                return\n",
    "\n",
    "            bytes_stream = b\"\"\n",
    "            stop_detection = False\n",
    "            frame_counter = 0\n",
    "\n",
    "            def listen_for_stop():\n",
    "                nonlocal stop_detection\n",
    "                while not stop_detection:\n",
    "                    audio_path = self.record_audio(duration=4)\n",
    "                    if audio_path:\n",
    "                        command = self.recognize_speech(audio_path)\n",
    "                        if command and \"stop\" in command.lower():\n",
    "                            logger.info(\"Stop command detected\")\n",
    "                            stop_detection = True\n",
    "                            break\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "            self.executor.submit(listen_for_stop)\n",
    "            self.speak_text(\"Iam Looking for money.\")\n",
    "\n",
    "            while not stop_detection:\n",
    "                try:\n",
    "                    for chunk in stream.iter_content(chunk_size=1024):\n",
    "\n",
    "                        if stop_detection:\n",
    "                            break\n",
    "\n",
    "                        bytes_stream += chunk\n",
    "                        a = bytes_stream.find(b'\\xff\\xd8')\n",
    "                        b = bytes_stream.find(b'\\xff\\xd9')\n",
    "\n",
    "                        if a != -1 and b != -1:\n",
    "                            jpg = bytes_stream[a:b+2]\n",
    "                            bytes_stream = bytes_stream[b+2:]\n",
    "                            frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                            if frame is None:\n",
    "                                continue\n",
    "\n",
    "                            cv2.imshow(\"Camera Stream\", frame)\n",
    "                            cv2.waitKey(1)\n",
    "\n",
    "                            frame_counter += 1\n",
    "                            if frame_counter % 20 != 0:\n",
    "                                continue\n",
    "\n",
    "                            results = self.currency_model(frame)\n",
    "                            predictions = results.pred[0]  # tensor: (N, 6)\n",
    "\n",
    "                            current_time = time.time()\n",
    "                            for *xyxy, conf, cls_id in predictions.tolist():\n",
    "                                if conf > 0.6:\n",
    "                                    cls_name = self.currency_model.names[int(cls_id)]\n",
    "                                    if cls_name not in last_announcement_time or \\\n",
    "                                       (current_time - last_announcement_time[cls_name]) > announcement_cooldown:\n",
    "                                        logger.info(f\"Detected currency: {cls_name} with confidence {conf:.2f}\")\n",
    "                                        self.speak_text(f\"{cls_name} detected\")\n",
    "                                        last_announcement_time[cls_name] = current_time\n",
    "\n",
    "                except requests.exceptions.Timeout:\n",
    "                    continue\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    logger.error(f\"Stream error: {str(e)}\")\n",
    "                    self.speak_text(\"Camera stream interrupted\")\n",
    "                    break\n",
    "\n",
    "            self.speak_text(\"Currency detection session complete\")\n",
    "            logger.info(\"Currency detection completed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error: {str(e)}\")\n",
    "            self.speak_text(\"An unexpected error occurred during currency detection.\")\n",
    "\n",
    "\n",
    "\n",
    "    def make_call(self, name: str) -> None:\n",
    "        \"\"\"Simulate making a call to the specified name.\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Attempting to call {name}...\")\n",
    "            self.speak_text(f\"Calling {name}\")\n",
    "            # Placeholder for actual call logic\n",
    "            time.sleep(1)  # Simulate call delay\n",
    "            self.speak_text(f\"Call to {name} completed (placeholder)\")\n",
    "            logger.info(f\"Call to {name} processed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Call failed: {str(e)}\")\n",
    "            self.speak_text(\"An error occurred while making the call\")\n",
    "\n",
    "    def detect_hazards(self) -> None:\n",
    "        \"\"\"Detect hazards using YOLO model and announce them via speech. Stops on voice command.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting hazards detection...\")\n",
    "            self.speak_text(\"Say 'stop' when you want to end the session.\")\n",
    "            \n",
    "            # Check if YOLO model is loaded\n",
    "            if self.hazard_model is None:\n",
    "                logger.error(\"YOLO model not initialized\")\n",
    "                self.speak_text(\"Hazard detection not available. YOLO model not initialized.\")\n",
    "                return\n",
    "            \n",
    "            # Set up time tracking for detection frequency\n",
    "            last_announcement_time = {}\n",
    "            announcement_cooldown = 3  # seconds between repeated announcements\n",
    "            \n",
    "            # Start streaming from camera\n",
    "            stream = requests.get(CAMERA_URL, stream=True)\n",
    "\n",
    "            if stream.status_code != 200:\n",
    "                self.speak_text(\"Failed to connect to the camera\")\n",
    "                logger.error(\"Camera connection failed\")\n",
    "                return\n",
    "                \n",
    "            bytes_stream = b\"\"\n",
    "            stop_detection = False\n",
    "            frame_counter = 0\n",
    "            \n",
    "            # Create a separate thread to listen for the stop command\n",
    "            def listen_for_stop():\n",
    "                nonlocal stop_detection\n",
    "                while not stop_detection:\n",
    "                    audio_path = self.record_audio(duration=4)\n",
    "                    if audio_path:\n",
    "                        command = self.recognize_speech(audio_path)\n",
    "                        if command and \"stop\" in command.lower():\n",
    "                            logger.info(\"Stop command detected\")\n",
    "                            stop_detection = True\n",
    "                            break\n",
    "                    time.sleep(0.1)\n",
    "            \n",
    "            # Start the listening thread\n",
    "            stop_thread = self.executor.submit(listen_for_stop)\n",
    "            \n",
    "            self.speak_text(\"Looking for objects.\")\n",
    "            \n",
    "            while not stop_detection:\n",
    "                try:\n",
    "                    for chunk in stream.iter_content(chunk_size=1024):\n",
    "                        if stop_detection:\n",
    "                            break\n",
    "                            \n",
    "                        bytes_stream += chunk\n",
    "                        a = bytes_stream.find(b'\\xff\\xd8')  # Start of JPEG\n",
    "                        b = bytes_stream.find(b'\\xff\\xd9')  # End of JPEG\n",
    "                        \n",
    "                        if a != -1 and b != -1:\n",
    "                            jpg = bytes_stream[a:b+2]\n",
    "                            bytes_stream = bytes_stream[b+2:]\n",
    "                            \n",
    "                            frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                            if frame is None:\n",
    "                                continue\n",
    "                            \n",
    "                            frame_counter += 1\n",
    "                            if frame_counter % 15 != 0:\n",
    "                                cv2.imshow(\"Camera Stream\", frame)\n",
    "                                cv2.waitKey(1)\n",
    "                                continue\n",
    "                                        \n",
    "                            # Detect objects using YOLO\n",
    "                            results = self.hazard_model(frame)[0]\n",
    "                            annotated_frame = results.plot()\n",
    "\n",
    "                            current_time = time.time()\n",
    "                \n",
    "                            # Process and announce detected objects\n",
    "                            for box in results.boxes:\n",
    "                                cls_id = int(box.cls.item())\n",
    "                                cls_name = self.hazard_model.names[cls_id]\n",
    "                                conf = box.conf.item()\n",
    "\n",
    "                                # Only announce if confidence is high enough\n",
    "                                if conf > 0.5:\n",
    "                                    # Avoid repeating the same object too frequently\n",
    "                                    if cls_name not in last_announcement_time or \\\n",
    "                                    (current_time - last_announcement_time[cls_name]) > announcement_cooldown:\n",
    "                                        \n",
    "                                        logger.info(f\"Detected hazard: {cls_name} with confidence {conf:.2f}\")\n",
    "                                        self.speak_text(f\"{cls_name} ahead\")\n",
    "                                        logger.info(f\"{cls_name} ahead\")\n",
    "                                    \n",
    "                                        last_announcement_time[cls_name] = current_time\n",
    "                            \n",
    "                            \n",
    "                            # Display the frame with bounding boxes\n",
    "                            cv2.imshow(\"Camera Stream\", annotated_frame)\n",
    "                            cv2.waitKey(1)\n",
    "                \n",
    "                \n",
    "                except requests.exceptions.Timeout:\n",
    "                    # Continue if timeout occurs in the request\n",
    "                    continue\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    logger.error(f\"Stream error: {str(e)}\")\n",
    "                    self.speak_text(\"Camera stream interrupted\")\n",
    "                    break\n",
    "                    \n",
    "            self.speak_text(\"Hazard detection session complete\")\n",
    "            logger.info(\"Hazard detection completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Hazards detection failed: {str(e)}\")\n",
    "            self.speak_text(\"An error occurred during hazards detection\")\n",
    "\n",
    "    def run(self) -> None:\n",
    "        \"\"\"Main execution loop with wake word detection, general mode, and mode switching.\"\"\"\n",
    "        logger.info(\"Starting Vision Assistant. Listening for 'Hey Vision!'...\")\n",
    "        try:\n",
    "            while not self.shutdown_flag:\n",
    "                pcm = self.audio_stream.read(self.porcupine.frame_length, exception_on_overflow=False)\n",
    "                pcm = struct.unpack_from(\"h\" * self.porcupine.frame_length, pcm)\n",
    "\n",
    "                if self.porcupine.process(pcm) >= 0:\n",
    "                    logger.info(\"Wake word 'Hey Vision' detected!\")\n",
    "                    self.speak_text(\"Hello friend how can i help you today\")\n",
    "                 \n",
    "                    self.is_active = True  # Enter general mode directly\n",
    "                    # General mode (hub mode)\n",
    "                    while self.is_active and not self.is_assistance_mode and not self.is_currency_mode and not self.is_call_mode and not self.is_hazards_mode:\n",
    "                        time.sleep(0.1)\n",
    "                        \n",
    "                        audio_path = self.record_audio(duration=3)\n",
    "                        if audio_path:\n",
    "                            command = self.recognize_speech(audio_path)\n",
    "                            if command:\n",
    "                                command_lower = command.lower().strip()\n",
    "                                logger.info(f\"Recognized command: {command}\")\n",
    "                                if \"close\" in command_lower:\n",
    "                                    logger.info(\"Close command detected! Shutting down...\")\n",
    "                                    self.speak_text(\"Goodbye, shutting down now\")\n",
    "                                    self.shutdown_flag = True\n",
    "                                    break\n",
    "                                elif \"assistance\" in command_lower or \"assistant\" in command_lower:\n",
    "                                    logger.info(\"Switching to assistance mode!\")\n",
    "                                    self.speak_text(\"Switching to assistance mode\")\n",
    "                                    self.is_assistance_mode = True\n",
    "                                    break\n",
    "                                elif \"money\" in command_lower or \"currency\" in command_lower:\n",
    "                                    logger.info(\"Switching to currency detection mode!\")\n",
    "                                    self.speak_text(\"Switching to currency detection mode\")\n",
    "                                    self.is_currency_mode = True\n",
    "                                    break\n",
    "                                elif \"call\" in command_lower:\n",
    "                                    logger.info(\"Switching to call mode!\")\n",
    "                                    self.speak_text(\"Switching to call mode\")\n",
    "                                    self.is_call_mode = True\n",
    "                                    break\n",
    "                                elif \"hazard\" in command_lower or \"dangerous\" in command_lower:\n",
    "                                    logger.info(\"Switching to hazards mode!\")\n",
    "                                    self.speak_text(\"Switching to hazards mode\")\n",
    "                                    self.is_hazards_mode = True\n",
    "                                    break\n",
    "                                else:\n",
    "                                    logger.info(\"I didn't catch that, Please try again or say 'close' to exit\")\n",
    "                                    self.speak_text(\"I didn't catch that, Please try again or say 'close' to exit\")\n",
    "                                    continue\n",
    "\n",
    "                            else:\n",
    "                                logger.warning(\"No command recognized\")\n",
    "                                self.speak_text(\"You can say 'assistance', 'money', 'call', or 'hazards' to proceed, or 'close' to exit\")\n",
    "                                continue\n",
    "                                \n",
    "\n",
    "                # Assistance mode loop\n",
    "                if self.is_assistance_mode:\n",
    "\n",
    "                    while self.is_assistance_mode and not self.shutdown_flag:\n",
    "                        audio_path = self.record_audio(duration=3)\n",
    "                        if not audio_path:\n",
    "                            logger.warning(\"Failed to record audio in assistance mode\")\n",
    "                            self.speak_text(\"Failed to record your command. Please try again\")\n",
    "                            continue\n",
    "\n",
    "                        command = self.recognize_speech(audio_path)\n",
    "                        if not command:\n",
    "                            logger.warning(\"No command recognized in assistance mode\")\n",
    "                            self.speak_text(\"Please try again or say 'back' to return\")\n",
    "                            continue\n",
    "\n",
    "                        command_lower = command.lower().strip()\n",
    "                        logger.info(f\"Recognized command in assistance mode: {command}\")\n",
    "\n",
    "                        if \"close\" in command_lower:\n",
    "                            logger.info(\"Close command detected! Shutting down...\")\n",
    "                            self.speak_text(\"Goodbye, shutting down now\")\n",
    "                            self.shutdown_flag = True\n",
    "                            break\n",
    "                        elif \"back\" in command_lower:\n",
    "                            logger.info(\"Returning to general mode\")\n",
    "                            self.speak_text(\"Returning to general mode\")\n",
    "                            self.is_assistance_mode = False\n",
    "                            break\n",
    "                        else:\n",
    "                            success = self.process_command(command)\n",
    "                            if success is False:\n",
    "                                logger.warning(\"Command processing failed in assistance mode\")\n",
    "                                self.speak_text(\"Command could not be processed. Please try again\")\n",
    "                            else:\n",
    "                                self.speak_text(\"Say 'back' to return or 'close' to exit\")\n",
    "\n",
    "\n",
    "                # Currency detection mode\n",
    "                if self.is_currency_mode:\n",
    "                    self.detect_currency()  # Automatically take a photo and process it\n",
    "                    \n",
    "                    while not self.shutdown_flag or self.is_currency_mode:\n",
    "                        # Wait for \"back\" or \"close\" after detection\n",
    "                        self.speak_text(\"Say 'back' to return or 'close' to exit\")\n",
    "                        audio_path = self.record_audio(duration=3)\n",
    "                        if audio_path:\n",
    "                            command = self.recognize_speech(audio_path)\n",
    "                            if command:\n",
    "                                command_lower = command.lower().strip()\n",
    "                                logger.info(f\"Recognized command in currency mode: {command}\")\n",
    "                                if \"close\" in command_lower:\n",
    "                                    logger.info(\"Close command detected! Shutting down...\")\n",
    "                                    self.speak_text(\"Goodbye, shutting down now\")\n",
    "                                    self.shutdown_flag = True\n",
    "                                    break\n",
    "                                elif \"back\" in command_lower:\n",
    "                                    logger.info(\"Returning to general mode\")\n",
    "                                    self.speak_text(\"Returning to general mode\")\n",
    "                                    self.is_currency_mode = False\n",
    "                                    break\n",
    "\n",
    "                # Call mode\n",
    "                if self.is_call_mode:\n",
    "                    self.speak_text(\"Call mode active. Who do you want to call?\")\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "                    audio_path = self.record_audio(duration=3)\n",
    "                    if audio_path:\n",
    "                        name = self.recognize_speech(audio_path)\n",
    "                        if name:\n",
    "                            name_lower = name.lower().strip()\n",
    "                            logger.info(f\"Recognized name in call mode: {name}\")\n",
    "                            if \"close\" in name_lower:\n",
    "                                logger.info(\"Close command detected! Shutting down...\")\n",
    "                                self.speak_text(\"Goodbye, shutting down now\")\n",
    "                                self.shutdown_flag = True\n",
    "                                break\n",
    "                            elif \"back\" in name_lower:\n",
    "                                logger.info(\"Returning to general mode\")\n",
    "                                self.speak_text(\"Returning to general mode\")\n",
    "                                self.is_call_mode = False\n",
    "                            else:\n",
    "                                self.make_call(name)\n",
    "                                self.speak_text(\"Say 'back' to return or 'close' to exit\")\n",
    "                        else:\n",
    "                            logger.warning(\"No name recognized in call mode\")\n",
    "                            self.speak_text(\"Please try again or say 'back' to return\")\n",
    "                    else:\n",
    "                        logger.warning(\"Failed to record audio in call mode\")\n",
    "                        self.speak_text(\"Failed to record your command. Please try again\")\n",
    "\n",
    "                # Hazards mode\n",
    "                if self.is_hazards_mode:\n",
    "                    self.detect_hazards()  # Connect to camera and process\n",
    "                    \n",
    "                    # Wait for \"back\" or \"close\" after detection\n",
    "                    while not self.shutdown_flag or self.is_hazards_mode:\n",
    "                        self.speak_text(\"Say 'back' to return or 'close' to exit\")\n",
    "                        audio_path = self.record_audio(duration=3)\n",
    "                        if audio_path:\n",
    "                            command = self.recognize_speech(audio_path)\n",
    "                            if command:\n",
    "                                command_lower = command.lower().strip()\n",
    "                                logger.info(f\"Recognized command in hazards mode: {command}\")\n",
    "                                if \"close\" in command_lower:\n",
    "                                    logger.info(\"Close command detected! Shutting down...\")\n",
    "                                    self.speak_text(\"Goodbye, shutting down now\")\n",
    "                                    self.shutdown_flag = True\n",
    "                                    break\n",
    "                                elif \"back\" in command_lower:\n",
    "                                    logger.info(\"Returning to general mode\")\n",
    "                                    self.speak_text(\"Returning to general mode\")\n",
    "                                    self.is_hazards_mode = False\n",
    "                                    break\n",
    "                            \n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"Initiating graceful shutdown via keyboard interrupt...\")\n",
    "            self.shutdown_flag = True\n",
    "        \n",
    "        finally:\n",
    "            logger.info(\"Performing cleanup...\")\n",
    "            self.cleanup()\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        self.audio_stream.close()\n",
    "        self.pa.terminate()\n",
    "        self.porcupine.delete()\n",
    "        self.executor.shutdown(wait=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = VisionAssistant()\n",
    "    assistant.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
